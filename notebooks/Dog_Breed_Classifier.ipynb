{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Dog Breed Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "wVRbueA8jo3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "%load_ext tensorboard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "\n",
        "# We are running on Tensorflow 2.x\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4X_m-kpjo37",
        "colab_type": "text"
      },
      "source": [
        "# Project Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F10eW-__Lx5",
        "colab_type": "text"
      },
      "source": [
        "## Stanford Dog Dataset\n",
        "\n",
        "This simple Dog-breed classifier is based on [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbmQ4SD2L3uF",
        "colab_type": "text"
      },
      "source": [
        "### Retrieving through TFDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09zh01dPq5BM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "(raw_train_dataset, raw_validation_dataset, raw_test_dataset), dataset_info = tfds.load('stanford_dogs', \n",
        "                                  with_info=True, \n",
        "                                  split=['train[:70%]', 'train[70%:90%]', 'train[90%:]'],\n",
        "                                  as_supervised=True,\n",
        "                                )\n",
        "\n",
        "breed_names = dataset_info.features['label'].names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4VE29P0-_Ij",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m4x6D6Yduuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 224 # All images will be resized to 224x224 (which is ideal for MobileNetV2)\n",
        "BATCH_SIZE= 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGqnSURJV61V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_image(image):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image\n",
        "\n",
        "# Standard preprocess dataset\n",
        "def preprocess_dataset(dataset):\n",
        "  dataset = dataset.map(lambda image, label: (format_image(image), label))\n",
        "  dataset = dataset.shuffle(1000).batch(BATCH_SIZE)\n",
        "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "347c6jXUBtxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standard train dataset, without any augmentation\n",
        "std_train_dataset = raw_train_dataset.map(lambda image, label: (format_image(image), label))\n",
        "\n",
        "validation_dataset = preprocess_dataset(raw_validation_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQcaprPuj6G-",
        "colab_type": "text"
      },
      "source": [
        "## Image Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3I3DD_69qUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Central crop, similar like zooming\n",
        "def central_crop(image):\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  image = tf.image.central_crop(image, 0.7)\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image\n",
        "\n",
        "# Horizontal flip\n",
        "def horizontal_flip(image):\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  image = tf.image.flip_left_right(image)\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image\n",
        "\n",
        "# Rotate 90degree\n",
        "def rot90(image):\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  image = tf.image.rot90(image)\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image\n",
        "\n",
        "# Rotate 270 degree, which is the other way\n",
        "def rot270(image):\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  image = tf.image.rot90(image, k=3)\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image\n",
        "\n",
        "cropped_dataset = raw_train_dataset.shuffle(1000).take(8000).map(lambda image, label: (central_crop(image), label))\n",
        "horflip_dataset = raw_train_dataset.shuffle(1000).take(1000).map(lambda image, label: (horizontal_flip(image), label))\n",
        "rot90_dataset = raw_train_dataset.shuffle(1000).take(3500).map(lambda image, label: (rot90(image), label))\n",
        "rot270_dataset = raw_train_dataset.shuffle(1000).take(3500).map(lambda image, label: (rot270(image), label))\n",
        "\n",
        "# Combine all dataset\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "augmented_dataset = std_train_dataset.concatenate(cropped_dataset)\n",
        "augmented_dataset = augmented_dataset.concatenate(horflip_dataset)\n",
        "augmented_dataset = augmented_dataset.concatenate(rot90_dataset)\n",
        "augmented_dataset = augmented_dataset.concatenate(rot270_dataset)\n",
        "\n",
        "# Shuffle, repeat, batch, prefetch\n",
        "augmented_dataset = augmented_dataset.shuffle(1000).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9KCafBdjo4b",
        "colab_type": "text"
      },
      "source": [
        "## Creating Neural Network\n",
        "\n",
        "We are using MobileNetV2 as our base model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PMfYUYLKjo4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  mobilev2 = keras.applications.MobileNetV2(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "  # Fine-tuning the base model\n",
        "  mobilev2.trainable = True\n",
        "  for layer in mobilev2.layers:\n",
        "    if layer.name.find('Conv_1'):\n",
        "      layer.trainable = True\n",
        "    elif layer.name == 'out_relu':\n",
        "      layer.trainable = True\n",
        "    else:\n",
        "      layer.trainable = False\n",
        "\n",
        "  # Using MobileNetV2\n",
        "  model.add(mobilev2)\n",
        "\n",
        "  # Flatten the convolution and put to DNN\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(keras.layers.Dense(1024, activation='relu'))\n",
        "  model.add(keras.layers.Dropout(0.3))\n",
        "  model.add(keras.layers.Dense(512, activation='relu'))\n",
        "  \n",
        "  # Lastly use DNN with output shape 120 because there are 120 breeds\n",
        "  model.add(keras.layers.Dense(120, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Tce7dEnhjo44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Afp0xek0ULhi",
        "colab_type": "text"
      },
      "source": [
        "## Training our Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXWd3qCAcJSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove logs of previous training to use Tensorboard\n",
        "!rm -rf ./logs/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71VKyRdlsXY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.00001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvxkPKxDUNho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(augmented_dataset,\n",
        "          validation_data=validation_dataset,\n",
        "          epochs=50,\n",
        "          steps_per_epoch=200, \n",
        "          validation_steps=50,\n",
        "          callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogs9Bp2ggIG4",
        "colab_type": "text"
      },
      "source": [
        "### Plotting the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIELs_QZgG6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_result(history):\n",
        "  acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "  plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "  plt.title('Training & Validation accuracy') \n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss') \n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training & Validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot_result(model.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD5Vz_ABfLie",
        "colab_type": "text"
      },
      "source": [
        "### Viewing in Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIaPL_lW57Ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j4s4CStjo4_",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating our Neural Network\n",
        "Now that the training phase has ended, let's evaluate with our test dataset. Before that, we should preprocess our test_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ3YzNMWisXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = preprocess_dataset(raw_test_dataset)\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNgwjKGprb6i",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating with file upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeA9YmBO6HSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standard function to decode and resize image\n",
        "def decode_img_from_path(file_path):\n",
        "  image = tf.io.read_file(file_path)\n",
        "  image = tf.image.decode_jpeg(image, channels=3) # The file should be JPEG\n",
        "  # image = tf.image.decode_png(image, channels=3) # If the file is PNG\n",
        "  return format_image(image) # Also used in Validation and Test Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3kC2FWV6Ikp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "upload_dataset = tf.data.Dataset.from_tensor_slices([list(uploaded.keys())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1nI2FFJ6WDM",
        "colab_type": "text"
      },
      "source": [
        "### Upload manually with Google Colab toolbar\n",
        "\n",
        "In case our file is too big for `files.upload()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLT7ssykrez6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_dataset = tf.data.Dataset.from_tensor_slices(['some_dog_image.jpg'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jd2kW9B6Sma",
        "colab_type": "text"
      },
      "source": [
        "### Predicting the uploaded files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-GhZjXn6N4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_dataset = upload_dataset.map(lambda image_path: decode_img_from_path(image_path))\n",
        "upload_dataset = upload_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "predictions = model.predict(upload_dataset)\n",
        "\n",
        "for pred in predictions:\n",
        "  breeds_pct, breeds_idx = tf.math.top_k(pred, k=3)\n",
        "  breeds_pct = breeds_pct.numpy()\n",
        "  breeds_idx = breeds_idx.numpy()\n",
        "  print(\"Predictions:\")\n",
        "  for i in range(3):\n",
        "    print(\"{} ({}%)\".format(breed_names[breeds_idx[i]], breeds_pct[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUMcJjpZOMYo",
        "colab_type": "text"
      },
      "source": [
        "## Saving our Model\n",
        "\n",
        "Since I'm satisfied with the performance of the model, I want to export the model to be able to be used by my Web app.\n",
        "\n",
        "HDF5 file will contain:\n",
        "\n",
        "- Architecture of model to recreate\n",
        "- Weights of the model\n",
        "- Training configuration\n",
        "- State of the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_yBkM1ZWtie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqJjhJuwYzZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save it in Google Drive\n",
        "model.save('/content/drive/My Drive/ML Project/Dog Breeds/stanford_dogs_20200307.h5') # Use .h5 extension to save to HDF5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FaIlHw769-D",
        "colab_type": "text"
      },
      "source": [
        "### Loading our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8BGmKQ3XsMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = keras.models.load_model('/content/drive/My Drive/ML Project/Dog Breeds/stanford_dogs_20200307.h5')\n",
        "loaded_model.summary()\n",
        "\n",
        "loaded_model.evaluate(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRMCN3cB78f4",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "Dataset\n",
        "- [Stanford Dogs dataset for Fine-Grained Visual Categorization](http://vision.stanford.edu/aditya86/ImageNetDogs/)\n",
        "- [Tensorflow Datasets](https://www.tensorflow.org/datasets)\n",
        "\n",
        "Preprocessing Data\n",
        "- [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data)\n",
        "- [Load images using tf.data](https://www.tensorflow.org/tutorials/load_data/images#load_using_tfdata)\n",
        "\n",
        "MobileNetV2\n",
        "- [MobileNetV2: The Next Generation of On-Device Computer Vision Networks](https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html)\n",
        "\n",
        "Saving Keras Model\n",
        "- [Save and load models](https://www.tensorflow.org/tutorials/keras/save_and_load)\n",
        "- [FAQ - Keras Documentation](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model)"
      ]
    }
  ]
}